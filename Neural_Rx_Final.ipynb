{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 04:31:53.596629: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-23 04:31:53.631490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755941513.666969  296775 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755941513.677907  296775 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755941513.707091  296775 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755941513.707127  296775 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755941513.707133  296775 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755941513.707136  296775 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-23 04:31:53.722642: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n",
      "Sat Aug 23 04:31:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8              5W /   55W |    3515MiB /  12282MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3784      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A   1429969      C   ...iniforge3/envs/sionna1.1/bin/python       3500MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "!nvidia-smi\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "from sionna.phy.mimo import StreamManagement\n",
    "\n",
    "#from sionna.phy.ofdm import CSIGridMapper\n",
    "from sionna.phy.ofdm import ResourceGrid, ResourceGridMapper, ResourceGridDemapper, LSChannelEstimator, LMMSEEqualizer\n",
    "from sionna.phy.ofdm import OFDMModulator, OFDMDemodulator, RemoveNulledSubcarriers, ZFEqualizer\n",
    "\n",
    "from sionna.phy.channel.tr38901 import Antenna, AntennaArray, CDL, UMi, UMa, RMa\n",
    "from sionna.phy.channel import gen_single_sector_topology as gen_topology\n",
    "from sionna.phy.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel\n",
    "from sionna.phy.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel\n",
    "\n",
    "from sionna.phy.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.phy.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "from sionna.phy.mapping import Mapper, Demapper, BinarySource, QAMSource\n",
    "\n",
    "from sionna.phy.utils import ebnodb2no, sim_ber\n",
    "from sionna.phy.utils.metrics import compute_ber\n",
    "# from sionna.ofdm import CSIGridMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHY Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m TxPower         \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m((TxPower_dBm\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     16\u001b[0m TxPower_SC      \u001b[38;5;241m=\u001b[39m TxPower\u001b[38;5;241m/\u001b[39m(num_SC)\n\u001b[0;32m---> 17\u001b[0m TxPower_SC_dBm  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlog10(TxPower_SC\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Noise Power\u001b[39;00m\n\u001b[1;32m     20\u001b[0m noise_psd       \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m174\u001b[39m                                  \u001b[38;5;66;03m# in dBm/Hz\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "scenario = \"umi\"\n",
    "carrier_frequency = 5.3e9\n",
    "direction = \"uplink\"\n",
    "num_ut = 1\n",
    "batch_size = 10000\n",
    "\n",
    "num_RB   = 8\n",
    "num_symbols = 14\n",
    "num_SC = 96\n",
    "fft_size = 12*num_RB\n",
    "subcarrier_spacing = 30e3\n",
    "\n",
    "## Tx Power\n",
    "TxPower_dBm     = 10 # in dBm\n",
    "TxPower         = 10**((TxPower_dBm-30)/10)\n",
    "TxPower_SC      = TxPower/(num_SC)\n",
    "TxPower_SC_dBm  = 10*np.log10(TxPower_SC*1000)\n",
    "\n",
    "# Noise Power\n",
    "noise_psd       = -174                                  # in dBm/Hz\n",
    "noise_figure    = 9                                     # in dB\n",
    "noise_SC_Watt   = 10**((noise_psd + noise_figure - 30)/10)*subcarrier_spacing\n",
    "noise_SC_dBm    = 10*np.log10(noise_SC_Watt*1000)\n",
    "\n",
    "print(\"Tx_Power:\",TxPower_SC_dBm)\n",
    "print(\"Noise:\",noise_SC_dBm)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "# Define the UT antenna array\n",
    "ut_array = Antenna(polarization=\"single\",\n",
    "                   polarization_type=\"V\",\n",
    "                   antenna_pattern=\"omni\",\n",
    "                   carrier_frequency=carrier_frequency)\n",
    "\n",
    "# Define the BS antenna array\n",
    "bs_array = AntennaArray(num_rows=1,\n",
    "                             num_cols=1, # We want to transmitter to be equiped with the 16 rx antennas\n",
    "                             vertical_spacing=0.5,\n",
    "                             horizontal_spacing=0.5,\n",
    "                             polarization_type=\"V\",\n",
    "                             antenna_pattern=\"omni\",\n",
    "                             polarization=\"single\",\n",
    "                             carrier_frequency=5.3e9)\n",
    "\n",
    "# Create channel model\n",
    "channel_model = UMi(carrier_frequency=carrier_frequency,\n",
    "                    o2i_model=\"low\",\n",
    "                    ut_array=ut_array,\n",
    "                    bs_array=bs_array,\n",
    "                    direction=direction,\n",
    "                    enable_pathloss=True,\n",
    "                    enable_shadow_fading=True)\n",
    "\n",
    "# Generate the topology\n",
    "ut_dist = 10\n",
    "topology = gen_topology(batch_size, num_ut, scenario,min_bs_ut_dist=ut_dist, min_ut_velocity=0.33, max_ut_velocity=0.33,indoor_probability=1)\n",
    "\n",
    "# Set the topology\n",
    "channel_model.set_topology(*topology)\n",
    "ut_loc = topology[0]\n",
    "bs_loc = topology[1]\n",
    "ut_vel = topology[4]\n",
    "\n",
    "# The number of transmitted streams is equal to the number of UT antennas\n",
    "num_streams_per_tx = 1\n",
    "\n",
    "# Create an RX-TX association matrix\n",
    "# rx_tx_association[i,j]=1 means that receiver i gets at least one stream\n",
    "# from transmitter j. Depending on the transmission direction (uplink or downlink),\n",
    "# the role of UT and BS can change. However, as we have only a single\n",
    "# transmitter and receiver, this does not matter:\n",
    "rx_tx_association = np.zeros([1, num_ut])\n",
    "rx_tx_association[:, 0] = 1\n",
    "#rx_tx_association[:, 1] = 1\n",
    "\n",
    "# Instantiate a StreamManagement object\n",
    "# This determines which data streams are determined for which receiver.\n",
    "# In this simple setup, this is fairly simple. However, it can get complicated\n",
    "# for simulations with many transmitters and receivers.\n",
    "sm = StreamManagement(rx_tx_association, num_streams_per_tx)\n",
    "\n",
    "rg = ResourceGrid(num_ofdm_symbols=14,\n",
    "                  fft_size=fft_size,\n",
    "                  subcarrier_spacing=subcarrier_spacing,\n",
    "                  num_tx=num_ut,\n",
    "                  num_streams_per_tx=num_streams_per_tx,\n",
    "                  cyclic_prefix_length=0,\n",
    "                  pilot_pattern = \"kronecker\",\n",
    "                  pilot_ofdm_symbol_indices = [1])\n",
    "rg.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Communication Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits_per_symbol = 2 # QPSK modulation\n",
    "coderate = 0.3 # The code rate\n",
    "n = int(rg.num_data_symbols*num_bits_per_symbol)  # Number of coded bits\n",
    "k = int(n*coderate) # Number of information bits\n",
    "\n",
    "# The binary source will create batches of information bits\n",
    "binary_source = BinarySource()\n",
    "qam_source = QAMSource(num_bits_per_symbol)\n",
    "\n",
    "# The encoder maps information bits to coded bits\n",
    "#encoder = LDPC5GEncoder(k, n)\n",
    "\n",
    "# The mapper maps blocks of information bits to constellation symbols\n",
    "mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
    "\n",
    "# The resource grid mapper maps symbols onto an OFDM resource grid\n",
    "rg_mapper = ResourceGridMapper(rg)\n",
    "\n",
    "# CSI-RS mapper\n",
    "#csi_mapper = CSIGridMapper(rg)\n",
    "\n",
    "#rg_demap = ResourceGridDemapper(rg, sm)\n",
    "\n",
    "# This function removes nulled subcarriers from any tensor having the shape of a resource grid\n",
    "remove_nulled_scs = RemoveNulledSubcarriers(rg)\n",
    "# The LS channel estimator will provide channel estimates and error variances\n",
    "ls_est = LSChannelEstimator(rg, interpolation_type=\"nn\")\n",
    "\n",
    "# CSI-RS estimator will provide the raw channel estimates\n",
    "#csi_est = CSIrsChannelEstimator(rg, sm)\n",
    "#csi_est = CSIrsChannelEstimator(rg, sm, TxPower_SC, interpolation_type = 'lin')\n",
    "\n",
    "# The LMMSE equalizer will provide soft symbols together with noise variance estimates\n",
    "zf_equ = ZFEqualizer(rg, sm)\n",
    "\n",
    "# The demapper produces LLR for all coded bits\n",
    "demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
    "\n",
    "# The decoder provides hard-decisions on the information bits\n",
    "#decoder = LDPC5GDecoder(encoder, hard_out=True)\n",
    "\n",
    "# OFDM CHannel\n",
    "ofdm_channel = OFDMChannel(channel_model, rg, add_awgn=True, normalize_channel=False, return_channel=True)\n",
    "channel_freq = ApplyOFDMChannel(add_awgn=True)\n",
    "frequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Classical Communication System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received Signal Shape: (10000, 1, 1, 14, 96)\n",
      "Received Power :  tf.Tensor(2.2255253e-12, shape=(), dtype=float32)\n",
      "Received Pilot Pattern Power :  tf.Tensor(3.072867e-11, shape=(), dtype=float32)\n",
      "Pilot Pattern Power :  tf.Tensor(0.9999998, shape=(), dtype=float32)\n",
      "CSI Est NMSE : 6.2850675e-05\n",
      "BER: 0.2613760817307692\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# --------- Transmitter ---------\n",
    "b = binary_source([batch_size, num_ut, rg.num_streams_per_tx, n])  # n must equal (#data_REs * bits_per_sym)\n",
    "# c = encoder(b)  # keep commented for uncoded link\n",
    "\n",
    "x = mapper(b)\n",
    "x_map    = np.sqrt(TxPower_SC) * x                  # map bits -> constellation symbols\n",
    "x_rg = rg_mapper(x_map)              # map to OFDM resource grid (data REs only)\n",
    "\n",
    "# --------- Channel ---------\n",
    "a, tau = channel_model(num_time_samples=rg.num_ofdm_symbols,\n",
    "                       sampling_frequency=1/rg.ofdm_symbol_duration)\n",
    "h_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=False)\n",
    "\n",
    "# --------- Receive ---------\n",
    "no = noise_SC_Watt\n",
    "y  = channel_freq(x_rg, h_freq, no)\n",
    "print(\"Received Signal Shape:\", y.shape)  # e.g., (N,1,1,S,F)\n",
    "print(\"Received Power : \", tf.reduce_mean(tf.abs(y)**2))\n",
    "\n",
    "# Channel estimation \n",
    "'''noise_power = 0.001 * np.mean(np.abs(h_freq)**2)\n",
    "noise = (np.random.randn(*h_freq.shape) + 1j * np.random.randn(*h_freq.shape)) / np.sqrt(2)\n",
    "h_freq_d_DL_hat  = h_freq + noise * np.sqrt(noise_power)'''\n",
    "\n",
    "h_freq_d_DL_hat, _ = ls_est (y, no)\n",
    "# ZF equalization\n",
    "x_hat, no_eff = zf_equ(y, h_freq_d_DL_hat, tf.zeros_like(h_freq_d_DL_hat), no)\n",
    "x_hat = x_hat / np.sqrt(TxPower_SC)\n",
    "\n",
    "# Demap to bit LLRs for **data REs only**\n",
    "llr = demapper(x_hat, no_eff)  # shape typically (N, 1, 1, E) or (N,1,1,S,F,B) depending on demapper\n",
    "\n",
    "# --------- Uncoded hard decisions (NO LDPC decoder here) ---------\n",
    "# Flatten both LLRs and labels, align lengths, and compute BER\n",
    "llr_flat = tf.reshape(llr, [tf.shape(llr)[0], -1])              # (N, E)\n",
    "b_hat    = tf.cast(llr_flat > 0.0, tf.float32)                  # (N, E)\n",
    "\n",
    "b_flat   = tf.reshape(tf.cast(b, tf.float32), [tf.shape(b)[0], -1])  # (N, n)\n",
    "\n",
    "# Align in case shapes differ by a few bits (shouldn't if n = #data_REs * B)\n",
    "T_pred = tf.shape(b_hat)[1]\n",
    "T_true = tf.shape(b_flat)[1]\n",
    "#T_min  = tf.minimum(T_pred, T_true)\n",
    "#b_hat  = b_hat[:, :T_min]\n",
    "#b_flat = b_flat[:, :T_min]\n",
    "\n",
    "# --------- Metrics ---------\n",
    "mse = tf.reduce_mean(tf.abs(h_freq_d_DL_hat - h_freq)**2)\n",
    "nmse = mse / (tf.reduce_mean(tf.abs(h_freq)**2) + 1e-12)\n",
    "print(\"CSI Est NMSE :\", nmse.numpy())\n",
    "\n",
    "ber = compute_ber(b_flat, b_hat).numpy()\n",
    "print(\"BER:\", ber)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for NeuralRx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data  : (10000, 1, 14, 96) <dtype: 'complex64'>\n",
      "h_data  : (10000, 1, 14, 96) <dtype: 'complex64'>\n",
      "Ground Truth: (10000, 1, 1, 2496) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Prepare model inputs with SAME shapes you’ve been using\n",
    "#   - input_y : (B,1,S,F) complex64\n",
    "#   - input_h : (B,1,S,F) complex64\n",
    "#   - input_p : (B,1,S,F) complex64\n",
    "# ----------------------------\n",
    "# y is already (B,1,1,S,F) -> squeeze stream axis to get (B,1,S,F)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ----------------------------\n",
    "# Short-hands for dims\n",
    "# ----------------------------\n",
    "S = rg.num_ofdm_symbols  # 14\n",
    "F = num_SC               # 96  (active SC count used by your RG)\n",
    "B = batch_size\n",
    "\n",
    "y_data = tf.squeeze(y, axis=2)\n",
    "\n",
    "# h_freq is (B,1,1,1,1,S,F); remove antenna dims -> (B,S,F), then add channel dim -> (B,1,S,F)\n",
    "h_tmp  = tf.squeeze(h_freq_d_DL_hat, axis=[1,2,3,4])                              # (B,S,F)\n",
    "h_data = tf.expand_dims(h_tmp, axis=1)                                    # (B,1,S,F)\n",
    "\n",
    "# ----------------------------\n",
    "# Labels for training the NN receiver (same as before)\n",
    "# ----------------------------\n",
    "# If your loss expects flattened bits: (B,1,1,-1)\n",
    "#llr_probs = tf.sigmoid(llr)\n",
    "#llr_probs = tf.reshape(llr_probs, [B, 1, 1, -1])\n",
    "orig_bits =  tf.reshape(b_flat, [B, 1, 1, -1])\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"y_data  :\", y_data.shape, y_data.dtype)   # (B,1,S,F) complex64\n",
    "print(\"h_data  :\", h_data.shape, h_data.dtype)   # (B,1,S,F) complex64\n",
    "print(\"Ground Truth:\", orig_bits.shape, orig_bits.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Neural Rx : Divya's Version (Removed Pilots from Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:59:22.224212: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator adam/case/Assert/AssertGuard/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - loss: 0.6614 - val_loss: 0.5074\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.4965 - val_loss: 0.4959\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.4766 - val_loss: 0.4745\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.4655 - val_loss: 0.4741\n",
      "Epoch 5/100\n",
      "\u001b[1m171/250\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.4634"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 245\u001b[0m\n\u001b[1;32m    236\u001b[0m receiver_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    237\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr_schedule),\n\u001b[1;32m    238\u001b[0m     loss\u001b[38;5;241m=\u001b[39mbinary_sigmoid_cross_entropy\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m    242\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m\n\u001b[1;32m    243\u001b[0m )\n\u001b[0;32m--> 245\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mreceiver_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllr_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllr_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    253\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, regularizers\n",
    "from tensorflow.keras.layers import Layer, LayerNormalization, Dropout, Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "num_conv_channels = 128\n",
    "\n",
    "# =========================\n",
    "# Helper: dataset split\n",
    "# =========================\n",
    "def ensure_split(y_data, h_data, llr_probs, batch_size=32):\n",
    "    # If split already exists, reuse it\n",
    "    g = globals()\n",
    "    if 'train_indices' in g and 'val_indices' in g:\n",
    "        ti, vi = g['train_indices'], g['val_indices']\n",
    "    else:\n",
    "        dataset_size = y_data.shape[0]\n",
    "        idx = tf.random.shuffle(tf.range(dataset_size))\n",
    "        train_sz = int(0.8 * dataset_size)\n",
    "        ti, vi = idx[:train_sz], idx[train_sz:]\n",
    "        g['train_indices'], g['val_indices'] = ti, vi  # store globally for consistency\n",
    "\n",
    "    y_train = tf.gather(y_data, ti); y_val = tf.gather(y_data, vi)\n",
    "    h_train = tf.gather(h_data, ti); h_val = tf.gather(h_data, vi)\n",
    "    llr_train = tf.gather(llr_probs, ti); llr_val = tf.gather(llr_probs, vi)\n",
    "    return (y_train, y_val, h_train, h_val, llr_train, llr_val, ti, vi)\n",
    "\n",
    "# =========================\n",
    "# Learning-rate schedule\n",
    "# =========================\n",
    "class CustomLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"Warmup -> constant -> linear (or quadratic) decay driven by optimizer iterations.\"\"\"\n",
    "    def __init__(self, min_learning_rate, max_learning_rate, iter_limits, quad_decay=False):\n",
    "        super().__init__()\n",
    "        self.quad_decay = quad_decay\n",
    "        self.min_lr = tf.constant(min_learning_rate, tf.float32)\n",
    "        self.max_lr = tf.constant(max_learning_rate, tf.float32)\n",
    "        self.warmup_end = tf.constant(iter_limits[0], tf.float32)\n",
    "        self.decay_start = tf.constant(iter_limits[1], tf.float32)\n",
    "        self.last_iter = tf.constant(iter_limits[2], tf.float32)\n",
    "        if self.quad_decay:\n",
    "            self.dec_slope = self.max_lr / tf.square(self.last_iter - self.decay_start + 1e-12)\n",
    "        else:\n",
    "            self.dec_slope = (self.min_lr - self.max_lr) / (self.last_iter - self.decay_start + 1e-12)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        inc_slope = (self.max_lr - self.min_lr) / (self.warmup_end + 1e-12)\n",
    "        def phase_warmup(): return self.min_lr + step * inc_slope\n",
    "        def phase_const():  return self.max_lr\n",
    "        def phase_decay():\n",
    "            if self.quad_decay:\n",
    "                return self.dec_slope * tf.square(step - self.last_iter)\n",
    "            else:\n",
    "                return self.max_lr + self.dec_slope * (step - self.decay_start)\n",
    "        def phase_zero():   return tf.constant(0.0, tf.float32)\n",
    "        return tf.case([\n",
    "            (step < self.warmup_end, phase_warmup),\n",
    "            (tf.logical_and(step >= self.warmup_end, step < self.decay_start), phase_const),\n",
    "            (tf.logical_and(step >= self.decay_start, step < self.last_iter), phase_decay),\n",
    "        ], default=phase_zero, exclusive=True)\n",
    "\n",
    "# =========================\n",
    "# Loss\n",
    "# =========================\n",
    "def binary_sigmoid_cross_entropy(bit_labels, pred_llr):\n",
    "    \n",
    "    bit_labels = tf.cast(bit_labels, pred_llr.dtype)\n",
    "    valid_mask = tf.not_equal(bit_labels, -1)\n",
    "    bit_prob = tf.sigmoid(pred_llr)\n",
    "    bit_prob_masked = tf.boolean_mask(bit_prob, valid_mask)\n",
    "    bit_labels_masked = tf.boolean_mask(bit_labels, valid_mask)\n",
    "    bce = tf.keras.losses.binary_crossentropy(bit_labels_masked, bit_prob_masked)\n",
    "    return tf.reduce_mean(bce)\n",
    "\n",
    "# =========================\n",
    "# Depthwise residual block\n",
    "# =========================\n",
    "class DWResidualBlock(Layer):\n",
    "    def __init__(self, dropout_rate=0.10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.reg = regularizers.l2(1e-5)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = int(input_shape[-1])\n",
    "        self.ln1  = LayerNormalization(axis=(-1, -2, -3))\n",
    "        self.dw1  = DepthwiseConv2D(kernel_size=3, padding='same',\n",
    "                                    activation=None, depth_multiplier=1,\n",
    "                                    depthwise_regularizer=self.reg)\n",
    "        self.pw1  = Conv2D(filters=c, kernel_size=1, padding='same',\n",
    "                           activation=None, kernel_regularizer=self.reg)\n",
    "        self.drop1 = Dropout(self.dropout_rate)\n",
    "\n",
    "        self.ln2  = LayerNormalization(axis=(-1, -2, -3))\n",
    "        self.dw2  = DepthwiseConv2D(kernel_size=3, padding='same',\n",
    "                                    activation=None, depth_multiplier=1,\n",
    "                                    depthwise_regularizer=self.reg)\n",
    "        self.pw2  = Conv2D(filters=c, kernel_size=1, padding='same',\n",
    "                           activation=None, kernel_regularizer=self.reg)\n",
    "        self.drop2 = Dropout(self.dropout_rate)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        z = self.ln1(x);  z = relu(z)\n",
    "        z = self.dw1(z);  z = self.pw1(z)\n",
    "        z = self.drop1(z, training=training)\n",
    "\n",
    "        z = self.ln2(z);  z = relu(z)\n",
    "        z = self.dw2(z);  z = self.pw2(z)\n",
    "        z = self.drop2(z, training=training)\n",
    "\n",
    "        return x + z\n",
    "\n",
    "# =========================\n",
    "# Neural Receiver (3 inputs): y, h, p\n",
    "# =========================\n",
    "class NeuralReceiver(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.reg = regularizers.l2(1e-5)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_conv  = Conv2D(filters=num_conv_channels, kernel_size=3, padding='same',\n",
    "                                  activation=None, kernel_regularizer=self.reg)\n",
    "        self.res1 = DWResidualBlock(0)\n",
    "        self.res2 = DWResidualBlock(0)\n",
    "        self.res3 = DWResidualBlock(0)\n",
    "        self.res4 = DWResidualBlock(0)\n",
    "        self.output_conv = Conv2D(filters=num_bits_per_symbol, kernel_size=3, padding='same',\n",
    "                                  activation=None, kernel_regularizer=self.reg)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Inputs: (B,1,S,F) complex64\n",
    "        y, h = inputs\n",
    "        batch_size = tf.shape(y)[0]\n",
    "\n",
    "        # (B,1,S,F) -> (B,S,F,1)\n",
    "        y = tf.transpose(y, [0, 2, 3, 1])\n",
    "        h = tf.transpose(h, [0, 2, 3, 1])\n",
    "\n",
    "        # Per-sample power normalization\n",
    "        def norm_per_sample(t):\n",
    "            pow_t = tf.reduce_mean(tf.abs(h), axis=[1,2,3], keepdims=True) + 1e-6\n",
    "            return t / tf.cast(pow_t, t.dtype)\n",
    "\n",
    "        y_n = norm_per_sample(y)\n",
    "        h_n = norm_per_sample(h)\n",
    "\n",
    "        # RI concat -> (B,S,F,6)\n",
    "        y_ri = tf.concat([tf.math.real(y_n), tf.math.imag(y_n)], axis=-1)\n",
    "        h_ri = tf.concat([tf.math.real(h_n), tf.math.imag(h_n)], axis=-1)\n",
    "\n",
    "        z = tf.concat([y_ri, h_ri], axis=-1)\n",
    "\n",
    "        # Backbone\n",
    "        z = self.input_conv(z)\n",
    "        z = self.res1(z, training=training)\n",
    "        z = self.res2(z, training=training)\n",
    "        z = self.res3(z, training=training)\n",
    "        z = self.res4(z, training=training)\n",
    "        z = self.output_conv(z)  # (B,S,F,num_bits_per_symbol)\n",
    "\n",
    "        # ---- DROP PILOT SYMBOL (index 1) from logits so labels align ----\n",
    "        # z has S along axis=1: keep [0] and [2..S-1], remove index 1\n",
    "        z_data = tf.concat([z[:, :1, :, :], z[:, 2:, :, :]], axis=1)  # (B,S-1,F,bits)\n",
    "\n",
    "        # Flatten -> (B,1,1,(S-1)*F*bits) to match llr labels\n",
    "\n",
    "        z_flat = tf.reshape(z_data, [batch_size, 1, 1, -1])\n",
    "        return z_flat\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Build model (I/O shapes unchanged)\n",
    "# =========================\n",
    "input_y = tf.keras.Input(shape=(1, num_symbols, num_SC), dtype=tf.complex64)\n",
    "input_h = tf.keras.Input(shape=(1, num_symbols, num_SC), dtype=tf.complex64)\n",
    "\n",
    "receiver = NeuralReceiver()\n",
    "output_llrs = receiver([input_y, input_h])\n",
    "receiver_model = Model(inputs=[input_y, input_h], outputs=output_llrs)\n",
    "\n",
    "# =========================\n",
    "# Create pilots p_all (N,1,S,F) complex64, nonzero only at symbol 1\n",
    "# =========================\n",
    "# y_data/h_data/llr_probs must already exist at this point\n",
    "N = int(y_data.shape[0])\n",
    "S = int(num_symbols); F = int(num_SC)\n",
    "\n",
    "p_val = tf.complex(tf.constant(1.0, tf.float32), tf.constant(0.0, tf.float32))  # 1+0j\n",
    "sym1_mask = tf.one_hot(1, depth=S, dtype=tf.float32)       # (S,)\n",
    "sym1_mask = tf.reshape(sym1_mask, [1,1,S,1])               # (1,1,S,1)\n",
    "\n",
    "# All subcarriers as pilots on symbol 1 (comb optional below)\n",
    "#sc_mask = tf.ones([1,1,1,F], tf.float32)                   # (1,1,1,F)\n",
    "# # Optional comb pilot pattern:\n",
    "# pilot mask construction (you already have this)\n",
    "K = 1\n",
    "comb = tf.cast(tf.equal(tf.range(F) % K, 0), tf.float32)   # (F,)\n",
    "sc_mask = tf.reshape(comb, [1,1,1,F])                      # (1,1,1,F)\n",
    "\n",
    "# Apply mask to channel estimates (same shape)\n",
    "h_masked = h_data * tf.cast(sc_mask, tf.complex64)                             # (N,1,S,F)\n",
    "\n",
    "y_train, y_val, h_train, h_val, llr_train, llr_val, train_indices, val_indices = ensure_split(\n",
    "    y_data, h_data, orig_bits, batch_size=32\n",
    ")\n",
    "\n",
    "h_train = tf.gather(h_masked, train_indices)\n",
    "h_val   = tf.gather(h_masked, val_indices)\n",
    "\n",
    "# =========================\n",
    "# Compile & Train\n",
    "# =========================\n",
    "batch_size = 32\n",
    "total_epochs = 100\n",
    "steps_per_epoch = math.ceil(y_train.shape[0] / batch_size)\n",
    "\n",
    "warmup_epochs = 6\n",
    "decay_start_epoch = 22\n",
    "iter_limits = [\n",
    "    warmup_epochs * steps_per_epoch,\n",
    "    decay_start_epoch * steps_per_epoch,\n",
    "    total_epochs * steps_per_epoch\n",
    "]\n",
    "\n",
    "lr_schedule = CustomLRSchedule(\n",
    "    min_learning_rate=0.0,\n",
    "    max_learning_rate=1e-2,\n",
    "    iter_limits=iter_limits,\n",
    "    quad_decay=False\n",
    ")\n",
    "\n",
    "receiver_model.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss=binary_sigmoid_cross_entropy\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=6, restore_best_weights=True, min_delta=1e-4\n",
    ")\n",
    "\n",
    "history = receiver_model.fit(\n",
    "    [y_train, h_train],\n",
    "    llr_train,\n",
    "    validation_data=([y_val, h_val], llr_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=total_epochs,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Receiver BER (validation): 0.272864\n",
      "ZF Baseline BER (validation): 0.268252\n",
      "Relative BER change vs ZF: +1.72%\n"
     ]
    }
   ],
   "source": [
    "# ==== Evaluate after training (validation split) ====\n",
    "\n",
    "# 1) Predict LLRs with the neural receiver  (NOTE: 2 inputs!)\n",
    "llr_pred = receiver_model.predict([y_val, h_val], batch_size=32, verbose=0)  # (valN, 1, 1, B_data)\n",
    "\n",
    "# 2) Hard decisions -> predicted bits {0,1}; flatten to (valN, B_data)\n",
    "bits_pred_flat = tf.reshape(tf.cast(llr_pred > 0.0, tf.float32),\n",
    "                            [tf.shape(llr_pred)[0], -1])\n",
    "\n",
    "# 3) Ground-truth bits for the SAME validation subset; flatten to (valN, n_gt_bits)\n",
    "#    b shape from Tx step: (N, num_ut, rg.num_streams_per_tx, n_data_bits)\n",
    "b_all_flat = tf.squeeze(b, axis=[1, 2])                              # -> (N, n_data_bits)\n",
    "b_val_flat = tf.cast(tf.gather(b_all_flat, val_indices), tf.float32) # -> (valN, n_data_bits)\n",
    "\n",
    "# 4) Align lengths in case model outputs only data REs (e.g., pilot symbol dropped)\n",
    "pred_len = tf.shape(bits_pred_flat)[1]\n",
    "gt_len   = tf.shape(b_val_flat)[1]\n",
    "\n",
    "# If needed, truncate ground-truth to the prediction length (should match already if labels were made data-only)\n",
    "b_val_flat = b_val_flat[:, :pred_len]\n",
    "\n",
    "# 5) Neural receiver BER\n",
    "ber_neural = compute_ber(b_val_flat, bits_pred_flat).numpy()\n",
    "print(f\"Neural Receiver BER (validation): {ber_neural:.6f}\")\n",
    "\n",
    "# ----- Optional: compare with classical ZF baseline on the SAME val split -----\n",
    "try:\n",
    "    # If you still have 'llr' from the ZF demapper used earlier:\n",
    "    # llr shape typically: (N, num_symbols, num_SC, num_bits_per_symbol) or already flattened.\n",
    "    if len(llr.shape) > 2:\n",
    "        bits_zf = tf.cast(llr > 0.0, tf.float32)                     # -> (N, ..., ..., ...)\n",
    "        bits_zf_flat = tf.reshape(bits_zf, [tf.shape(bits_zf)[0], -1])  # -> (N, n_bits_total)\n",
    "    else:\n",
    "        bits_zf_flat = tf.cast(llr > 0.0, tf.float32)                # already (N, n_bits_total)\n",
    "\n",
    "    bits_zf_val_flat = tf.gather(bits_zf_flat, val_indices)          # -> (valN, n_bits_total)\n",
    "\n",
    "    # Align ZF length with model output (data-only length)\n",
    "    bits_zf_val_flat = bits_zf_val_flat[:, :pred_len]\n",
    "\n",
    "    ber_zf = compute_ber(b_val_flat, bits_zf_val_flat).numpy()\n",
    "    print(f\"ZF Baseline BER (validation): {ber_zf:.6f}\")\n",
    "    if ber_zf > 0:\n",
    "        print(f\"Relative BER change vs ZF: {(ber_neural - ber_zf) / ber_zf:+.2%}\")\n",
    "except Exception as e:\n",
    "    print(\"ZF baseline comparison skipped (llr not available or shape mismatch).\")\n",
    "    print(f\"Reason: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate 2 : NI's Version of DeepRx (Can Remove Pilots and Try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlockProperties:\n",
    "    \"\"\"Structure that holds all configurational parameters of the ResNet blocks.\"\"\"\n",
    "\n",
    "    num_blocks: int = 0\n",
    "    kernel_size: list = []\n",
    "    dilation_rate: list = []\n",
    "    num_filter: list = []\n",
    "\n",
    "class DeepRx:\n",
    "    \"\"\"DeepRx neural network model\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_ofdm_sym: int,\n",
    "        num_subcar: int,\n",
    "        num_ant: int,\n",
    "        res_net_config: ResNetBlockProperties,\n",
    "        num_output_llr: int,\n",
    "        use_submodels: bool,\n",
    "    ):\n",
    "        \"\"\"Initializes the network topology\"\"\"\n",
    "\n",
    "        # number of symbols in time: S\n",
    "        self.num_ofdm_sym = num_ofdm_sym\n",
    "        # number of subcarriers: F\n",
    "        self.num_subcar = num_subcar\n",
    "        # number of antennas: N_r\n",
    "        self.num_ant = num_ant\n",
    "        # number of output LLRs: B\n",
    "        self.num_output_llr = num_output_llr\n",
    "\n",
    "        # RX data input: complex value already split into two channels\n",
    "        y = tf.keras.layers.Input(shape=(num_ofdm_sym, num_subcar, 2 * num_ant), name=\"RX-Data-In\")\n",
    "        # TX pilots: complex value already split into two channels\n",
    "        x_p = tf.keras.layers.Input(shape=(num_ofdm_sym, num_subcar, 2), name=\"TX-Pilot-In\")\n",
    "        # raw channel estimate: complex value already split into two channels\n",
    "        h_r = tf.keras.layers.Input(shape=(num_ofdm_sym, num_subcar, 2 * num_ant), name=\"Raw-Channel-Est-In\")\n",
    "        # concatenate input layers\n",
    "        concat = tf.keras.layers.concatenate([y, x_p, h_r], name=\"Concat\")\n",
    "        # convolutional input layer\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), dilation_rate=(1, 1), padding=\"same\", activation=None, name=\"Conv-In\")(\n",
    "            concat\n",
    "        )\n",
    "        # construct ResNet blocks\n",
    "        for block_idx in range(res_net_config.num_blocks):\n",
    "            # generate ResNet block as compact sub-models\n",
    "            if use_submodels:\n",
    "                _, res_net_block = self.create_res_net_block(\n",
    "                    input=x,\n",
    "                    filter_size=tuple(res_net_config.kernel_size[block_idx]),\n",
    "                    dilation=tuple(res_net_config.dilation_rate[block_idx]),\n",
    "                    num_filter=res_net_config.num_filter[block_idx],\n",
    "                    res_net_block_idx=block_idx,\n",
    "                )\n",
    "                x = res_net_block(x)\n",
    "            # generate ResNet block with all sub-layers visible\n",
    "            else:\n",
    "                x, _ = self.create_res_net_block(\n",
    "                    input=x,\n",
    "                    filter_size=tuple(res_net_config.kernel_size[block_idx]),\n",
    "                    dilation=tuple(res_net_config.dilation_rate[block_idx]),\n",
    "                    num_filter=res_net_config.num_filter[block_idx],\n",
    "                    res_net_block_idx=block_idx,\n",
    "                )\n",
    "        # convolutional output layer: LLR\n",
    "        output = tf.keras.layers.Conv2D(\n",
    "            self.num_output_llr, (3, 3), dilation_rate=(1, 1), padding=\"same\", activation=None, name=\"Conv-Out\"\n",
    "        )(x)\n",
    "        # instantiate complete model\n",
    "        self.model = tf.keras.Model(inputs=[y, x_p, h_r], outputs=output, name=\"DeepRx\")\n",
    "\n",
    "    def create_res_net_block(\n",
    "        self,\n",
    "        input: tf.Tensor,\n",
    "        filter_size: tuple,\n",
    "        dilation: tuple,\n",
    "        num_filter: int,\n",
    "        res_net_block_idx: int,\n",
    "    ):\n",
    "        \"\"\"Creates the ResNet sub-blocks\"\"\"\n",
    "        x = tf.keras.layers.BatchNormalization(name=f\"BN-{res_net_block_idx}-0\")(input)\n",
    "        x = tf.keras.layers.ReLU(name=f\"ReLU-{res_net_block_idx}-0\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(\n",
    "            filters=num_filter,\n",
    "            kernel_size=filter_size,\n",
    "            dilation_rate=dilation,\n",
    "            depth_multiplier=1,\n",
    "            padding=\"same\",\n",
    "            name=f\"Separable-Conv-{res_net_block_idx}-0\",\n",
    "        )(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f\"BN-{res_net_block_idx}-1\")(x)\n",
    "        x = tf.keras.layers.ReLU(name=f\"ReLU-{res_net_block_idx}-1\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(\n",
    "            filters=num_filter,\n",
    "            kernel_size=filter_size,\n",
    "            dilation_rate=dilation,\n",
    "            depth_multiplier=1,\n",
    "            padding=\"same\",\n",
    "            name=f\"Separable-Conv-{res_net_block_idx}-1\",\n",
    "        )(x)\n",
    "\n",
    "        # When ResNet block's output depth is increased or decreased, also the residual path has to be up- or downsampled.\n",
    "        # This can be achieved via 1x1 convolutions.\n",
    "        if input.shape[3] != num_filter:\n",
    "            x_shortcut = tf.keras.layers.Conv2D(num_filter, (1, 1), name=f\"Conv-Depth-Adjust-{res_net_block_idx}\")(\n",
    "                input\n",
    "            )\n",
    "            # TODO: do we need additional BN and ReLU activation here?\n",
    "            x_shortcut = tf.keras.layers.BatchNormalization(name=f\"BN-{res_net_block_idx}-2\")(x_shortcut)\n",
    "            # x_shortcut = tf.keras.layers.ReLU(name=f\"ReLU-{res_net_block_idx}-2\")(x_shortcut)\n",
    "        else:\n",
    "            x_shortcut = input\n",
    "\n",
    "        output = tf.keras.layers.Add(name=f\"Add-{res_net_block_idx}\")([x_shortcut, x])\n",
    "\n",
    "        res_net_model = tf.keras.Model(inputs=input, outputs=output, name=f\"ResNet-Block-{res_net_block_idx}\")\n",
    "\n",
    "        return output, res_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def resnet_block(x, filters, dilation, name):\n",
    "    \"\"\"ResNet block with depthwise separable conv + skip connection\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    x = layers.SeparableConv2D(filters, kernel_size=(3,3), \n",
    "                               padding=\"same\", \n",
    "                               dilation_rate=dilation,\n",
    "                               activation='relu',\n",
    "                               name=f\"{name}_sepconv1\")(x)\n",
    "    x = layers.BatchNormalization(name=f\"{name}_bn1\")(x)\n",
    "\n",
    "    x = layers.SeparableConv2D(filters, kernel_size=(3,3), \n",
    "                               padding=\"same\", \n",
    "                               dilation_rate=dilation,\n",
    "                               activation=None,\n",
    "                               name=f\"{name}_sepconv2\")(x)\n",
    "    x = layers.BatchNormalization(name=f\"{name}_bn2\")(x)\n",
    "\n",
    "    # Skip connection (if channel mismatch, project)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1,1), padding=\"same\", name=f\"{name}_proj\")(shortcut)\n",
    "\n",
    "    x = layers.Add(name=f\"{name}_add\")([x, shortcut])\n",
    "    x = layers.Activation(\"relu\", name=f\"{name}_relu\")(x)\n",
    "    return x\n",
    "\n",
    "def build_deeprx(S, F, Nr, B):\n",
    "    \"\"\"\n",
    "    Build DeepRx CNN ResNet architecture\n",
    "    S, F : dimensions of resource grid\n",
    "    Nr   : number of Rx antennas\n",
    "    B    : output bits per symbol\n",
    "    \"\"\"\n",
    "\n",
    "    # Inputs\n",
    "    inp_Y  = Input(shape=(S, F, Nr), name=\"Y\")        # RX Data\n",
    "    inp_Xp = Input(shape=(S, F, 1), name=\"Xp\")        # TX Pilot\n",
    "    inp_Hr = Input(shape=(S, F, Nr), name=\"Hr\")       # Raw channel estimate\n",
    "\n",
    "    # Concatenate complex inputs along channel axis\n",
    "    zc = layers.Concatenate(axis=-1)([inp_Y, inp_Xp, inp_Hr])  # (S, F, Nc)\n",
    "\n",
    "    # Convert to real by splitting real & imag (here assume input is complex-as-real with 2 channels)\n",
    "    # If your data is already real-valued split, skip this part\n",
    "    z_real = layers.Concatenate(axis=-1)([tf.math.real(zc), tf.math.imag(zc)])\n",
    "\n",
    "    # Conv In\n",
    "    x = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\", name=\"conv_in\")(z_real)\n",
    "\n",
    "    # ResNet Blocks\n",
    "    x = resnet_block(x, 64,  (1,1), \"resblock1\")\n",
    "    x = resnet_block(x, 64,  (1,1), \"resblock2\")\n",
    "    x = resnet_block(x, 128, (2,3), \"resblock3\")\n",
    "    x = resnet_block(x, 128, (2,3), \"resblock4\")\n",
    "    x = resnet_block(x, 256, (2,3), \"resblock5\")\n",
    "    x = resnet_block(x, 256, (3,6), \"resblock6\")\n",
    "    x = resnet_block(x, 256, (2,3), \"resblock7\")\n",
    "    x = resnet_block(x, 128, (2,3), \"resblock8\")\n",
    "    x = resnet_block(x, 128, (2,3), \"resblock9\")\n",
    "    x = resnet_block(x, 64,  (1,1), \"resblock10\")\n",
    "    x = resnet_block(x, 64,  (1,1), \"resblock11\")\n",
    "\n",
    "    # Conv Out\n",
    "    x = layers.Conv2D(B, (1,1), padding=\"same\", activation=None, name=\"conv_out\")(x)\n",
    "\n",
    "    # LLR output\n",
    "    out = layers.Activation(\"linear\", name=\"llr_output\")(x)\n",
    "\n",
    "    model = Model(inputs=[inp_Y, inp_Xp, inp_Hr], outputs=out, name=\"DeepRx\")\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "S, F, Nr, B = 14, 72, 2, 4   # OFDM symbols, subcarriers, antennas, bits per symbol\n",
    "model = build_deeprx(S, F, Nr, B)\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
