{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 03:43:08.584469: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-21 03:43:08.593662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755765788.604351 1064722 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755765788.607377 1064722 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755765788.615256 1064722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755765788.615281 1064722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755765788.615282 1064722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755765788.615283 1064722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-21 03:43:08.617946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n",
      "Thu Aug 21 03:43:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8              4W /  125W |    7569MiB /  12282MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3743      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A    990047      C   ...iniforge3/envs/sionna1.1/bin/python       7554MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "!nvidia-smi\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "from sionna.phy.mimo import StreamManagement\n",
    "\n",
    "#from sionna.phy.ofdm import CSIGridMapper\n",
    "from sionna.phy.ofdm import ResourceGrid, ResourceGridMapper, ResourceGridDemapper, LSChannelEstimator, LMMSEEqualizer\n",
    "from sionna.phy.ofdm import OFDMModulator, OFDMDemodulator, RemoveNulledSubcarriers, ZFEqualizer\n",
    "\n",
    "from sionna.phy.channel.tr38901 import Antenna, AntennaArray, CDL, UMi, UMa, RMa\n",
    "from sionna.phy.channel import gen_single_sector_topology as gen_topology\n",
    "from sionna.phy.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel\n",
    "from sionna.phy.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel\n",
    "\n",
    "from sionna.phy.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.phy.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "from sionna.phy.mapping import Mapper, Demapper, BinarySource, QAMSource\n",
    "\n",
    "from sionna.phy.utils import ebnodb2no, sim_ber\n",
    "from sionna.phy.utils.metrics import compute_ber\n",
    "# from sionna.ofdm import CSIGridMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHY Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tx_Power: 0.17728766960431616\n",
      "Noise: -120.22878745280337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755765811.333069 1064722 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1755765811.333452 1064722 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755765814.622467 1064722 cuda_solvers.cc:175] Creating GpuSolver handles for stream 0x609262d84170\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = \"umi\"\n",
    "carrier_frequency = 5.3e9\n",
    "direction = \"uplink\"\n",
    "num_ut = 1\n",
    "batch_size = 10000\n",
    "\n",
    "num_RB   = 8\n",
    "num_symbols = 14\n",
    "num_SC = 96\n",
    "fft_size = 12*num_RB\n",
    "subcarrier_spacing = 30e3\n",
    "\n",
    "## Tx Power\n",
    "TxPower_dBm     = 20 # in dBm\n",
    "TxPower         = 10**((TxPower_dBm-30)/10)\n",
    "TxPower_SC      = TxPower/(num_SC)\n",
    "TxPower_SC_dBm  = 10*np.log10(TxPower_SC*1000)\n",
    "\n",
    "# Noise Power\n",
    "noise_psd       = -174                                  # in dBm/Hz\n",
    "noise_figure    = 9                                     # in dB\n",
    "noise_SC_Watt   = 10**((noise_psd + noise_figure - 30)/10)*subcarrier_spacing\n",
    "noise_SC_dBm    = 10*np.log10(noise_SC_Watt*1000)\n",
    "\n",
    "print(\"Tx_Power:\",TxPower_SC_dBm)\n",
    "print(\"Noise:\",noise_SC_dBm)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "# Define the UT antenna array\n",
    "ut_array = Antenna(polarization=\"single\",\n",
    "                   polarization_type=\"V\",\n",
    "                   antenna_pattern=\"omni\",\n",
    "                   carrier_frequency=carrier_frequency)\n",
    "\n",
    "# Define the BS antenna array\n",
    "bs_array = AntennaArray(num_rows=1,\n",
    "                             num_cols=1, # We want to transmitter to be equiped with the 16 rx antennas\n",
    "                             vertical_spacing=0.5,\n",
    "                             horizontal_spacing=0.5,\n",
    "                             polarization_type=\"V\",\n",
    "                             antenna_pattern=\"omni\",\n",
    "                             polarization=\"single\",\n",
    "                             carrier_frequency=5.3e9)\n",
    "\n",
    "# Create channel model\n",
    "channel_model = UMi(carrier_frequency=carrier_frequency,\n",
    "                    o2i_model=\"low\",\n",
    "                    ut_array=ut_array,\n",
    "                    bs_array=bs_array,\n",
    "                    direction=direction,\n",
    "                    enable_pathloss=True,\n",
    "                    enable_shadow_fading=True)\n",
    "\n",
    "# Generate the topology\n",
    "ut_dist = 10\n",
    "topology = gen_topology(batch_size, num_ut, scenario,min_bs_ut_dist=ut_dist, min_ut_velocity=0.33, max_ut_velocity=0.33,indoor_probability=0)\n",
    "\n",
    "# Set the topology\n",
    "channel_model.set_topology(*topology)\n",
    "ut_loc = topology[0]\n",
    "bs_loc = topology[1]\n",
    "ut_vel = topology[4]\n",
    "\n",
    "# The number of transmitted streams is equal to the number of UT antennas\n",
    "num_streams_per_tx = 1\n",
    "\n",
    "# Create an RX-TX association matrix\n",
    "# rx_tx_association[i,j]=1 means that receiver i gets at least one stream\n",
    "# from transmitter j. Depending on the transmission direction (uplink or downlink),\n",
    "# the role of UT and BS can change. However, as we have only a single\n",
    "# transmitter and receiver, this does not matter:\n",
    "rx_tx_association = np.zeros([1, num_ut])\n",
    "rx_tx_association[:, 0] = 1\n",
    "#rx_tx_association[:, 1] = 1\n",
    "\n",
    "# Instantiate a StreamManagement object\n",
    "# This determines which data streams are determined for which receiver.\n",
    "# In this simple setup, this is fairly simple. However, it can get complicated\n",
    "# for simulations with many transmitters and receivers.\n",
    "sm = StreamManagement(rx_tx_association, num_streams_per_tx)\n",
    "\n",
    "rg = ResourceGrid(num_ofdm_symbols=14,\n",
    "                  fft_size=fft_size,\n",
    "                  subcarrier_spacing=subcarrier_spacing,\n",
    "                  num_tx=num_ut,\n",
    "                  num_streams_per_tx=num_streams_per_tx,\n",
    "                  cyclic_prefix_length=0,\n",
    "                  pilot_pattern = \"kronecker\",\n",
    "                  pilot_ofdm_symbol_indices = [1])\n",
    "rg.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Communication Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits_per_symbol = 2 # QPSK modulation\n",
    "coderate = 0.3 # The code rate\n",
    "n = int(rg.num_data_symbols*num_bits_per_symbol)  # Number of coded bits\n",
    "k = int(n*coderate) # Number of information bits\n",
    "\n",
    "# The binary source will create batches of information bits\n",
    "binary_source = BinarySource()\n",
    "qam_source = QAMSource(num_bits_per_symbol)\n",
    "\n",
    "# The encoder maps information bits to coded bits\n",
    "#encoder = LDPC5GEncoder(k, n)\n",
    "\n",
    "# The mapper maps blocks of information bits to constellation symbols\n",
    "mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
    "\n",
    "# The resource grid mapper maps symbols onto an OFDM resource grid\n",
    "rg_mapper = ResourceGridMapper(rg)\n",
    "\n",
    "# CSI-RS mapper\n",
    "#csi_mapper = CSIGridMapper(rg)\n",
    "\n",
    "#rg_demap = ResourceGridDemapper(rg, sm)\n",
    "\n",
    "# This function removes nulled subcarriers from any tensor having the shape of a resource grid\n",
    "remove_nulled_scs = RemoveNulledSubcarriers(rg)\n",
    "# The LS channel estimator will provide channel estimates and error variances\n",
    "ls_est = LSChannelEstimator(rg, interpolation_type=\"nn\")\n",
    "\n",
    "# CSI-RS estimator will provide the raw channel estimates\n",
    "#csi_est = CSIrsChannelEstimator(rg, sm)\n",
    "#csi_est = CSIrsChannelEstimator(rg, sm, TxPower_SC, interpolation_type = 'lin')\n",
    "\n",
    "# The LMMSE equalizer will provide soft symbols together with noise variance estimates\n",
    "zf_equ = ZFEqualizer(rg, sm)\n",
    "\n",
    "# The demapper produces LLR for all coded bits\n",
    "demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
    "\n",
    "# The decoder provides hard-decisions on the information bits\n",
    "#decoder = LDPC5GDecoder(encoder, hard_out=True)\n",
    "\n",
    "# OFDM CHannel\n",
    "ofdm_channel = OFDMChannel(channel_model, rg, add_awgn=True, normalize_channel=False, return_channel=True)\n",
    "channel_freq = ApplyOFDMChannel(add_awgn=True)\n",
    "frequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Classical Communication System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received Signal Shape: (10000, 1, 1, 14, 96)\n",
      "Received Power :  tf.Tensor(2.5731547e-10, shape=(), dtype=float32)\n",
      "Received Pilot Pattern Power :  tf.Tensor(3.5542744e-09, shape=(), dtype=float32)\n",
      "Pilot Pattern Power :  tf.Tensor(0.9999998, shape=(), dtype=float32)\n",
      "CSI Est NMSE : 2.9604811e-05\n",
      "BER: 0.03083477564102564\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# --------- Transmitter ---------\n",
    "b = binary_source([batch_size, num_ut, rg.num_streams_per_tx, n])  # n must equal (#data_REs * bits_per_sym)\n",
    "# c = encoder(b)  # keep commented for uncoded link\n",
    "\n",
    "x = mapper(b)\n",
    "x_map    = np.sqrt(TxPower_SC) * x                  # map bits -> constellation symbols\n",
    "x_rg = rg_mapper(x_map)              # map to OFDM resource grid (data REs only)\n",
    "\n",
    "# --------- Channel ---------\n",
    "a, tau = channel_model(num_time_samples=rg.num_ofdm_symbols,\n",
    "                       sampling_frequency=1/rg.ofdm_symbol_duration)\n",
    "h_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=False)\n",
    "\n",
    "# --------- Receive ---------\n",
    "no = noise_SC_Watt\n",
    "y  = channel_freq(x_rg, h_freq, no)\n",
    "print(\"Received Signal Shape:\", y.shape)  # e.g., (N,1,1,S,F)\n",
    "print(\"Received Power : \", tf.reduce_mean(tf.abs(y)**2))\n",
    "\n",
    "# Channel estimation \n",
    "'''noise_power = 0.001 * np.mean(np.abs(h_freq)**2)\n",
    "noise = (np.random.randn(*h_freq.shape) + 1j * np.random.randn(*h_freq.shape)) / np.sqrt(2)\n",
    "h_freq_d_DL_hat  = h_freq + noise * np.sqrt(noise_power)'''\n",
    "\n",
    "h_freq_d_DL_hat, _ = ls_est (y, no)\n",
    "# ZF equalization\n",
    "x_hat, no_eff = zf_equ(y, h_freq_d_DL_hat, tf.zeros_like(h_freq_d_DL_hat), no)\n",
    "x_hat = x_hat / np.sqrt(TxPower_SC)\n",
    "\n",
    "# Demap to bit LLRs for **data REs only**\n",
    "llr = demapper(x_hat, no_eff)  # shape typically (N, 1, 1, E) or (N,1,1,S,F,B) depending on demapper\n",
    "\n",
    "# --------- Uncoded hard decisions (NO LDPC decoder here) ---------\n",
    "# Flatten both LLRs and labels, align lengths, and compute BER\n",
    "llr_flat = tf.reshape(llr, [tf.shape(llr)[0], -1])              # (N, E)\n",
    "b_hat    = tf.cast(llr_flat > 0.0, tf.float32)                  # (N, E)\n",
    "\n",
    "b_flat   = tf.reshape(tf.cast(b, tf.float32), [tf.shape(b)[0], -1])  # (N, n)\n",
    "\n",
    "# Align in case shapes differ by a few bits (shouldn't if n = #data_REs * B)\n",
    "T_pred = tf.shape(b_hat)[1]\n",
    "T_true = tf.shape(b_flat)[1]\n",
    "T_min  = tf.minimum(T_pred, T_true)\n",
    "b_hat  = b_hat[:, :T_min]\n",
    "b_flat = b_flat[:, :T_min]\n",
    "\n",
    "# --------- Metrics ---------\n",
    "mse = tf.reduce_mean(tf.abs(h_freq_d_DL_hat - h_freq)**2)\n",
    "nmse = mse / (tf.reduce_mean(tf.abs(h_freq)**2) + 1e-12)\n",
    "print(\"CSI Est NMSE :\", nmse.numpy())\n",
    "\n",
    "ber = compute_ber(b_flat, b_hat).numpy()\n",
    "print(\"BER:\", ber)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for NeuralRx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data  : (10000, 1, 14, 96) <dtype: 'complex64'>\n",
      "h_data  : (10000, 1, 14, 96) <dtype: 'complex64'>\n",
      "llr_probs: (10000, 1, 1, 2496) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Prepare model inputs with SAME shapes you’ve been using\n",
    "#   - input_y : (B,1,S,F) complex64\n",
    "#   - input_h : (B,1,S,F) complex64\n",
    "#   - input_p : (B,1,S,F) complex64\n",
    "# ----------------------------\n",
    "# y is already (B,1,1,S,F) -> squeeze stream axis to get (B,1,S,F)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ----------------------------\n",
    "# Short-hands for dims\n",
    "# ----------------------------\n",
    "S = rg.num_ofdm_symbols  # 14\n",
    "F = num_SC               # 96  (active SC count used by your RG)\n",
    "B = batch_size\n",
    "\n",
    "y_data = tf.squeeze(y, axis=2)\n",
    "\n",
    "# h_freq is (B,1,1,1,1,S,F); remove antenna dims -> (B,S,F), then add channel dim -> (B,1,S,F)\n",
    "h_tmp  = tf.squeeze(h_freq_d_DL_hat, axis=[1,2,3,4])                              # (B,S,F)\n",
    "h_data = tf.expand_dims(h_tmp, axis=1)                                    # (B,1,S,F)\n",
    "\n",
    "# ----------------------------\n",
    "# Labels for training the NN receiver (same as before)\n",
    "# ----------------------------\n",
    "# If your loss expects flattened bits: (B,1,1,-1)\n",
    "llr_probs = tf.sigmoid(llr)\n",
    "llr_probs = tf.reshape(llr_probs, [B, 1, 1, -1])\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"y_data  :\", y_data.shape, y_data.dtype)   # (B,1,S,F) complex64\n",
    "print(\"h_data  :\", h_data.shape, h_data.dtype)   # (B,1,S,F) complex64\n",
    "print(\"llr_probs:\", llr_probs.shape, llr_probs.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Neural Rx : Divya's Version (Removed Pilots from Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755765933.990245 1068720 service.cc:152] XLA service 0x759c00004fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755765933.990287 1068720 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 Laptop GPU, Compute Capability 8.9\n",
      "2025-08-21 03:45:34.189661: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-08-21 03:45:34.352982: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator adam/case/Assert/AssertGuard/Assert\n",
      "I0000 00:00:1755765935.772283 1068720 cuda_dnn.cc:529] Loaded cuDNN version 90500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.7205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755765943.427105 1068720 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 42ms/step - loss: 0.7123 - val_loss: 0.6846\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.5369 - val_loss: 0.1236\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.1427 - val_loss: 0.0904\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.1053 - val_loss: 0.0769\n",
      "Epoch 5/100\n",
      "\u001b[1m163/250\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0809"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 245\u001b[0m\n\u001b[1;32m    236\u001b[0m receiver_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    237\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr_schedule),\n\u001b[1;32m    238\u001b[0m     loss\u001b[38;5;241m=\u001b[39mbinary_sigmoid_cross_entropy\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m    242\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m\n\u001b[1;32m    243\u001b[0m )\n\u001b[0;32m--> 245\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mreceiver_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllr_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllr_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    253\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:221\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m ):\n\u001b[1;32m    220\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sionna1.1/lib/python3.10/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, regularizers\n",
    "from tensorflow.keras.layers import Layer, LayerNormalization, Dropout, Conv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "num_conv_channels = 128\n",
    "\n",
    "# =========================\n",
    "# Helper: dataset split\n",
    "# =========================\n",
    "def ensure_split(y_data, h_data, llr_probs, batch_size=32):\n",
    "    # If split already exists, reuse it\n",
    "    g = globals()\n",
    "    if 'train_indices' in g and 'val_indices' in g:\n",
    "        ti, vi = g['train_indices'], g['val_indices']\n",
    "    else:\n",
    "        dataset_size = y_data.shape[0]\n",
    "        idx = tf.random.shuffle(tf.range(dataset_size))\n",
    "        train_sz = int(0.8 * dataset_size)\n",
    "        ti, vi = idx[:train_sz], idx[train_sz:]\n",
    "        g['train_indices'], g['val_indices'] = ti, vi  # store globally for consistency\n",
    "\n",
    "    y_train = tf.gather(y_data, ti); y_val = tf.gather(y_data, vi)\n",
    "    h_train = tf.gather(h_data, ti); h_val = tf.gather(h_data, vi)\n",
    "    llr_train = tf.gather(llr_probs, ti); llr_val = tf.gather(llr_probs, vi)\n",
    "    return (y_train, y_val, h_train, h_val, llr_train, llr_val, ti, vi)\n",
    "\n",
    "# =========================\n",
    "# Learning-rate schedule\n",
    "# =========================\n",
    "class CustomLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"Warmup -> constant -> linear (or quadratic) decay driven by optimizer iterations.\"\"\"\n",
    "    def __init__(self, min_learning_rate, max_learning_rate, iter_limits, quad_decay=False):\n",
    "        super().__init__()\n",
    "        self.quad_decay = quad_decay\n",
    "        self.min_lr = tf.constant(min_learning_rate, tf.float32)\n",
    "        self.max_lr = tf.constant(max_learning_rate, tf.float32)\n",
    "        self.warmup_end = tf.constant(iter_limits[0], tf.float32)\n",
    "        self.decay_start = tf.constant(iter_limits[1], tf.float32)\n",
    "        self.last_iter = tf.constant(iter_limits[2], tf.float32)\n",
    "        if self.quad_decay:\n",
    "            self.dec_slope = self.max_lr / tf.square(self.last_iter - self.decay_start + 1e-12)\n",
    "        else:\n",
    "            self.dec_slope = (self.min_lr - self.max_lr) / (self.last_iter - self.decay_start + 1e-12)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        inc_slope = (self.max_lr - self.min_lr) / (self.warmup_end + 1e-12)\n",
    "        def phase_warmup(): return self.min_lr + step * inc_slope\n",
    "        def phase_const():  return self.max_lr\n",
    "        def phase_decay():\n",
    "            if self.quad_decay:\n",
    "                return self.dec_slope * tf.square(step - self.last_iter)\n",
    "            else:\n",
    "                return self.max_lr + self.dec_slope * (step - self.decay_start)\n",
    "        def phase_zero():   return tf.constant(0.0, tf.float32)\n",
    "        return tf.case([\n",
    "            (step < self.warmup_end, phase_warmup),\n",
    "            (tf.logical_and(step >= self.warmup_end, step < self.decay_start), phase_const),\n",
    "            (tf.logical_and(step >= self.decay_start, step < self.last_iter), phase_decay),\n",
    "        ], default=phase_zero, exclusive=True)\n",
    "\n",
    "# =========================\n",
    "# Loss\n",
    "# =========================\n",
    "def binary_sigmoid_cross_entropy(bit_labels, pred_llr):\n",
    "    \n",
    "    bit_labels = tf.cast(bit_labels, pred_llr.dtype)\n",
    "    valid_mask = tf.not_equal(bit_labels, -1)\n",
    "    bit_prob = tf.sigmoid(pred_llr)\n",
    "    bit_prob_masked = tf.boolean_mask(bit_prob, valid_mask)\n",
    "    bit_labels_masked = tf.boolean_mask(bit_labels, valid_mask)\n",
    "    bce = tf.keras.losses.binary_crossentropy(bit_labels_masked, bit_prob_masked)\n",
    "    return tf.reduce_mean(bce)\n",
    "\n",
    "# =========================\n",
    "# Depthwise residual block\n",
    "# =========================\n",
    "class DWResidualBlock(Layer):\n",
    "    def __init__(self, dropout_rate=0.10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.reg = regularizers.l2(1e-5)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        c = int(input_shape[-1])\n",
    "        self.ln1  = LayerNormalization(axis=(-1, -2, -3))\n",
    "        self.dw1  = DepthwiseConv2D(kernel_size=3, padding='same',\n",
    "                                    activation=None, depth_multiplier=1,\n",
    "                                    depthwise_regularizer=self.reg)\n",
    "        self.pw1  = Conv2D(filters=c, kernel_size=1, padding='same',\n",
    "                           activation=None, kernel_regularizer=self.reg)\n",
    "        self.drop1 = Dropout(self.dropout_rate)\n",
    "\n",
    "        self.ln2  = LayerNormalization(axis=(-1, -2, -3))\n",
    "        self.dw2  = DepthwiseConv2D(kernel_size=3, padding='same',\n",
    "                                    activation=None, depth_multiplier=1,\n",
    "                                    depthwise_regularizer=self.reg)\n",
    "        self.pw2  = Conv2D(filters=c, kernel_size=1, padding='same',\n",
    "                           activation=None, kernel_regularizer=self.reg)\n",
    "        self.drop2 = Dropout(self.dropout_rate)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        z = self.ln1(x);  z = relu(z)\n",
    "        z = self.dw1(z);  z = self.pw1(z)\n",
    "        z = self.drop1(z, training=training)\n",
    "\n",
    "        z = self.ln2(z);  z = relu(z)\n",
    "        z = self.dw2(z);  z = self.pw2(z)\n",
    "        z = self.drop2(z, training=training)\n",
    "\n",
    "        return x + z\n",
    "\n",
    "# =========================\n",
    "# Neural Receiver (3 inputs): y, h, p\n",
    "# =========================\n",
    "class NeuralReceiver(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.reg = regularizers.l2(1e-5)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_conv  = Conv2D(filters=num_conv_channels, kernel_size=3, padding='same',\n",
    "                                  activation=None, kernel_regularizer=self.reg)\n",
    "        self.res1 = DWResidualBlock(0.10)\n",
    "        self.res2 = DWResidualBlock(0.10)\n",
    "        self.res3 = DWResidualBlock(0.10)\n",
    "        self.res4 = DWResidualBlock(0.10)\n",
    "        self.output_conv = Conv2D(filters=num_bits_per_symbol, kernel_size=3, padding='same',\n",
    "                                  activation=None, kernel_regularizer=self.reg)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Inputs: (B,1,S,F) complex64\n",
    "        y, h = inputs\n",
    "        batch_size = tf.shape(y)[0]\n",
    "\n",
    "        # (B,1,S,F) -> (B,S,F,1)\n",
    "        y = tf.transpose(y, [0, 2, 3, 1])\n",
    "        h = tf.transpose(h, [0, 2, 3, 1])\n",
    "\n",
    "        # Per-sample power normalization\n",
    "        def norm_per_sample(t):\n",
    "            pow_t = tf.reduce_mean(tf.abs(t), axis=[1,2,3], keepdims=True) + 1e-6\n",
    "            return t / tf.cast(pow_t, t.dtype)\n",
    "\n",
    "        y_n = norm_per_sample(y)\n",
    "        h_n = norm_per_sample(h)\n",
    "\n",
    "        # RI concat -> (B,S,F,6)\n",
    "        y_ri = tf.concat([tf.math.real(y_n), tf.math.imag(y_n)], axis=-1)\n",
    "        h_ri = tf.concat([tf.math.real(h_n), tf.math.imag(h_n)], axis=-1)\n",
    "\n",
    "        z = tf.concat([y_ri, h_ri], axis=-1)\n",
    "\n",
    "        # Backbone\n",
    "        z = self.input_conv(z)\n",
    "        z = self.res1(z, training=training)\n",
    "        z = self.res2(z, training=training)\n",
    "        z = self.res3(z, training=training)\n",
    "        z = self.res4(z, training=training)\n",
    "        z = self.output_conv(z)  # (B,S,F,num_bits_per_symbol)\n",
    "\n",
    "        # ---- DROP PILOT SYMBOL (index 1) from logits so labels align ----\n",
    "        # z has S along axis=1: keep [0] and [2..S-1], remove index 1\n",
    "        z_data = tf.concat([z[:, :1, :, :], z[:, 2:, :, :]], axis=1)  # (B,S-1,F,bits)\n",
    "\n",
    "        # Flatten -> (B,1,1,(S-1)*F*bits) to match llr labels\n",
    "\n",
    "        z_flat = tf.reshape(z_data, [batch_size, 1, 1, -1])\n",
    "        return z_flat\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Build model (I/O shapes unchanged)\n",
    "# =========================\n",
    "input_y = tf.keras.Input(shape=(1, num_symbols, num_SC), dtype=tf.complex64)\n",
    "input_h = tf.keras.Input(shape=(1, num_symbols, num_SC), dtype=tf.complex64)\n",
    "\n",
    "receiver = NeuralReceiver()\n",
    "output_llrs = receiver([input_y, input_h])\n",
    "receiver_model = Model(inputs=[input_y, input_h], outputs=output_llrs)\n",
    "\n",
    "# =========================\n",
    "# Create pilots p_all (N,1,S,F) complex64, nonzero only at symbol 1\n",
    "# =========================\n",
    "# y_data/h_data/llr_probs must already exist at this point\n",
    "N = int(y_data.shape[0])\n",
    "S = int(num_symbols); F = int(num_SC)\n",
    "\n",
    "p_val = tf.complex(tf.constant(1.0, tf.float32), tf.constant(0.0, tf.float32))  # 1+0j\n",
    "sym1_mask = tf.one_hot(1, depth=S, dtype=tf.float32)       # (S,)\n",
    "sym1_mask = tf.reshape(sym1_mask, [1,1,S,1])               # (1,1,S,1)\n",
    "\n",
    "# All subcarriers as pilots on symbol 1 (comb optional below)\n",
    "#sc_mask = tf.ones([1,1,1,F], tf.float32)                   # (1,1,1,F)\n",
    "# # Optional comb pilot pattern:\n",
    "# pilot mask construction (you already have this)\n",
    "K = 4\n",
    "comb = tf.cast(tf.equal(tf.range(F) % K, 0), tf.float32)   # (F,)\n",
    "sc_mask = tf.reshape(comb, [1,1,1,F])                      # (1,1,1,F)\n",
    "\n",
    "# Apply mask to channel estimates (same shape)\n",
    "h_masked = h_data * tf.cast(sc_mask, tf.complex64)                             # (N,1,S,F)\n",
    "\n",
    "y_train, y_val, h_train, h_val, llr_train, llr_val, train_indices, val_indices = ensure_split(\n",
    "    y_data, h_data, llr_probs, batch_size=32\n",
    ")\n",
    "\n",
    "h_train = tf.gather(h_masked, train_indices)\n",
    "h_val   = tf.gather(h_masked, val_indices)\n",
    "\n",
    "# =========================\n",
    "# Compile & Train\n",
    "# =========================\n",
    "batch_size = 32\n",
    "total_epochs = 100\n",
    "steps_per_epoch = math.ceil(y_train.shape[0] / batch_size)\n",
    "\n",
    "warmup_epochs = 6\n",
    "decay_start_epoch = 22\n",
    "iter_limits = [\n",
    "    warmup_epochs * steps_per_epoch,\n",
    "    decay_start_epoch * steps_per_epoch,\n",
    "    total_epochs * steps_per_epoch\n",
    "]\n",
    "\n",
    "lr_schedule = CustomLRSchedule(\n",
    "    min_learning_rate=0.0,\n",
    "    max_learning_rate=1e-3,\n",
    "    iter_limits=iter_limits,\n",
    "    quad_decay=False\n",
    ")\n",
    "\n",
    "receiver_model.compile(\n",
    "    optimizer=Adam(learning_rate=lr_schedule),\n",
    "    loss=binary_sigmoid_cross_entropy\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=6, restore_best_weights=True, min_delta=1e-4\n",
    ")\n",
    "\n",
    "history = receiver_model.fit(\n",
    "    [y_train, h_train],\n",
    "    llr_train,\n",
    "    validation_data=([y_val, h_val], llr_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=total_epochs,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Receiver BER (validation): 0.033323\n",
      "ZF Baseline BER (validation): 0.031689\n",
      "Relative BER change vs ZF: +5.16%\n"
     ]
    }
   ],
   "source": [
    "# ==== Evaluate after training (validation split) ====\n",
    "\n",
    "# 1) Predict LLRs with the neural receiver  (NOTE: 2 inputs!)\n",
    "llr_pred = receiver_model.predict([y_val, h_val], batch_size=32, verbose=0)  # (valN, 1, 1, B_data)\n",
    "\n",
    "# 2) Hard decisions -> predicted bits {0,1}; flatten to (valN, B_data)\n",
    "bits_pred_flat = tf.reshape(tf.cast(llr_pred > 0.0, tf.float32),\n",
    "                            [tf.shape(llr_pred)[0], -1])\n",
    "\n",
    "# 3) Ground-truth bits for the SAME validation subset; flatten to (valN, n_gt_bits)\n",
    "#    b shape from Tx step: (N, num_ut, rg.num_streams_per_tx, n_data_bits)\n",
    "b_all_flat = tf.squeeze(b, axis=[1, 2])                              # -> (N, n_data_bits)\n",
    "b_val_flat = tf.cast(tf.gather(b_all_flat, val_indices), tf.float32) # -> (valN, n_data_bits)\n",
    "\n",
    "# 4) Align lengths in case model outputs only data REs (e.g., pilot symbol dropped)\n",
    "pred_len = tf.shape(bits_pred_flat)[1]\n",
    "gt_len   = tf.shape(b_val_flat)[1]\n",
    "\n",
    "# If needed, truncate ground-truth to the prediction length (should match already if labels were made data-only)\n",
    "b_val_flat = b_val_flat[:, :pred_len]\n",
    "\n",
    "# 5) Neural receiver BER\n",
    "ber_neural = compute_ber(b_val_flat, bits_pred_flat).numpy()\n",
    "print(f\"Neural Receiver BER (validation): {ber_neural:.6f}\")\n",
    "\n",
    "# ----- Optional: compare with classical ZF baseline on the SAME val split -----\n",
    "try:\n",
    "    # If you still have 'llr' from the ZF demapper used earlier:\n",
    "    # llr shape typically: (N, num_symbols, num_SC, num_bits_per_symbol) or already flattened.\n",
    "    if len(llr.shape) > 2:\n",
    "        bits_zf = tf.cast(llr > 0.0, tf.float32)                     # -> (N, ..., ..., ...)\n",
    "        bits_zf_flat = tf.reshape(bits_zf, [tf.shape(bits_zf)[0], -1])  # -> (N, n_bits_total)\n",
    "    else:\n",
    "        bits_zf_flat = tf.cast(llr > 0.0, tf.float32)                # already (N, n_bits_total)\n",
    "\n",
    "    bits_zf_val_flat = tf.gather(bits_zf_flat, val_indices)          # -> (valN, n_bits_total)\n",
    "\n",
    "    # Align ZF length with model output (data-only length)\n",
    "    bits_zf_val_flat = bits_zf_val_flat[:, :pred_len]\n",
    "\n",
    "    ber_zf = compute_ber(b_val_flat, bits_zf_val_flat).numpy()\n",
    "    print(f\"ZF Baseline BER (validation): {ber_zf:.6f}\")\n",
    "    if ber_zf > 0:\n",
    "        print(f\"Relative BER change vs ZF: {(ber_neural - ber_zf) / ber_zf:+.2%}\")\n",
    "except Exception as e:\n",
    "    print(\"ZF baseline comparison skipped (llr not available or shape mismatch).\")\n",
    "    print(f\"Reason: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate 2 : NI's Version of DeepRx (Can Remove Pilots and Try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlockProperties:\n",
    "    \"\"\"Structure that holds all configurational parameters of the ResNet blocks.\"\"\"\n",
    "\n",
    "    num_blocks: int = 0\n",
    "    kernel_size: list = []\n",
    "    dilation_rate: list = []\n",
    "    num_filter: list = []\n",
    "\n",
    "class DeepRx:\n",
    "    \"\"\"DeepRx neural network model\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_ofdm_sym: int,\n",
    "        num_subcar: int,\n",
    "        num_ant: int,\n",
    "        res_net_config: ResNetBlockProperties,\n",
    "        num_output_llr: int,\n",
    "        use_submodels: bool,\n",
    "    ):\n",
    "        \"\"\"Initializes the network topology\"\"\"\n",
    "\n",
    "        # number of symbols in time: S\n",
    "        self.num_ofdm_sym = num_ofdm_sym\n",
    "        # number of subcarriers: F\n",
    "        self.num_subcar = num_subcar\n",
    "        # number of antennas: N_r\n",
    "        self.num_ant = num_ant\n",
    "        # number of output LLRs: B\n",
    "        self.num_output_llr = num_output_llr\n",
    "\n",
    "        # RX data input: complex value already split into two channels\n",
    "        y = tf.keras.layers.Input(shape=(num_ofdm_sym, num_subcar, 2 * num_ant), name=\"RX-Data-In\")\n",
    "        # TX pilots: complex value already split into two channels\n",
    "        x_p = tf.keras.layers.Input(shape=(num_ofdm_sym, num_subcar, 2), name=\"TX-Pilot-In\")\n",
    "        # raw channel estimate: complex value already split into two channels\n",
    "        h_r = tf.keras.layers.Input(shape=(num_ofdm_sym, num_subcar, 2 * num_ant), name=\"Raw-Channel-Est-In\")\n",
    "        # concatenate input layers\n",
    "        concat = tf.keras.layers.concatenate([y, x_p, h_r], name=\"Concat\")\n",
    "        # convolutional input layer\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), dilation_rate=(1, 1), padding=\"same\", activation=None, name=\"Conv-In\")(\n",
    "            concat\n",
    "        )\n",
    "        # construct ResNet blocks\n",
    "        for block_idx in range(res_net_config.num_blocks):\n",
    "            # generate ResNet block as compact sub-models\n",
    "            if use_submodels:\n",
    "                _, res_net_block = self.create_res_net_block(\n",
    "                    input=x,\n",
    "                    filter_size=tuple(res_net_config.kernel_size[block_idx]),\n",
    "                    dilation=tuple(res_net_config.dilation_rate[block_idx]),\n",
    "                    num_filter=res_net_config.num_filter[block_idx],\n",
    "                    res_net_block_idx=block_idx,\n",
    "                )\n",
    "                x = res_net_block(x)\n",
    "            # generate ResNet block with all sub-layers visible\n",
    "            else:\n",
    "                x, _ = self.create_res_net_block(\n",
    "                    input=x,\n",
    "                    filter_size=tuple(res_net_config.kernel_size[block_idx]),\n",
    "                    dilation=tuple(res_net_config.dilation_rate[block_idx]),\n",
    "                    num_filter=res_net_config.num_filter[block_idx],\n",
    "                    res_net_block_idx=block_idx,\n",
    "                )\n",
    "        # convolutional output layer: LLR\n",
    "        output = tf.keras.layers.Conv2D(\n",
    "            self.num_output_llr, (3, 3), dilation_rate=(1, 1), padding=\"same\", activation=None, name=\"Conv-Out\"\n",
    "        )(x)\n",
    "        # instantiate complete model\n",
    "        self.model = tf.keras.Model(inputs=[y, x_p, h_r], outputs=output, name=\"DeepRx\")\n",
    "\n",
    "    def create_res_net_block(\n",
    "        self,\n",
    "        input: tf.Tensor,\n",
    "        filter_size: tuple,\n",
    "        dilation: tuple,\n",
    "        num_filter: int,\n",
    "        res_net_block_idx: int,\n",
    "    ):\n",
    "        \"\"\"Creates the ResNet sub-blocks\"\"\"\n",
    "        x = tf.keras.layers.BatchNormalization(name=f\"BN-{res_net_block_idx}-0\")(input)\n",
    "        x = tf.keras.layers.ReLU(name=f\"ReLU-{res_net_block_idx}-0\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(\n",
    "            filters=num_filter,\n",
    "            kernel_size=filter_size,\n",
    "            dilation_rate=dilation,\n",
    "            depth_multiplier=1,\n",
    "            padding=\"same\",\n",
    "            name=f\"Separable-Conv-{res_net_block_idx}-0\",\n",
    "        )(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f\"BN-{res_net_block_idx}-1\")(x)\n",
    "        x = tf.keras.layers.ReLU(name=f\"ReLU-{res_net_block_idx}-1\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(\n",
    "            filters=num_filter,\n",
    "            kernel_size=filter_size,\n",
    "            dilation_rate=dilation,\n",
    "            depth_multiplier=1,\n",
    "            padding=\"same\",\n",
    "            name=f\"Separable-Conv-{res_net_block_idx}-1\",\n",
    "        )(x)\n",
    "\n",
    "        # When ResNet block's output depth is increased or decreased, also the residual path has to be up- or downsampled.\n",
    "        # This can be achieved via 1x1 convolutions.\n",
    "        if input.shape[3] != num_filter:\n",
    "            x_shortcut = tf.keras.layers.Conv2D(num_filter, (1, 1), name=f\"Conv-Depth-Adjust-{res_net_block_idx}\")(\n",
    "                input\n",
    "            )\n",
    "            # TODO: do we need additional BN and ReLU activation here?\n",
    "            x_shortcut = tf.keras.layers.BatchNormalization(name=f\"BN-{res_net_block_idx}-2\")(x_shortcut)\n",
    "            # x_shortcut = tf.keras.layers.ReLU(name=f\"ReLU-{res_net_block_idx}-2\")(x_shortcut)\n",
    "        else:\n",
    "            x_shortcut = input\n",
    "\n",
    "        output = tf.keras.layers.Add(name=f\"Add-{res_net_block_idx}\")([x_shortcut, x])\n",
    "\n",
    "        res_net_model = tf.keras.Model(inputs=input, outputs=output, name=f\"ResNet-Block-{res_net_block_idx}\")\n",
    "\n",
    "        return output, res_net_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
